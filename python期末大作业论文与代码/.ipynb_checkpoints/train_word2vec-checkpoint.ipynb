{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from gensim.models import word2vec\n",
    "import logging\n",
    "import pickle\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, LSTM,Masking,GRU,Bidirectional,Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)#这是一条用word2vec的必须命令，什么用我也不是很知道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open('word2vec/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('data/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_data = load_obj('df_train_data')\n",
    "df_predict_data = load_obj('df_predict_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_word2vec():\n",
    "    ##合并两组数据，让word2vec模型的数据量更大更全\n",
    "    df_all_data = pd.concat([df_train_data.content,df_predict_data.content], ignore_index = True).to_frame()\n",
    "    ls_all_data = list(df_all_data.content)#转换为列表形式方便训练\n",
    "    ##训练并保存word2vec\n",
    "    model = word2vec.Word2Vec(ls_all_data,size = 200, min_count = 5,workers = 20)#20线程\n",
    "    model.save('./word2vec/word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-28 10:40:47,860 : INFO : collecting all words and their counts\n",
      "2018-12-28 10:40:47,861 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-12-28 10:40:47,881 : INFO : PROGRESS: at sentence #10000, processed 79700 words, keeping 11971 word types\n",
      "2018-12-28 10:40:47,899 : INFO : PROGRESS: at sentence #20000, processed 156228 words, keeping 17968 word types\n",
      "2018-12-28 10:40:47,919 : INFO : PROGRESS: at sentence #30000, processed 233321 words, keeping 22637 word types\n",
      "2018-12-28 10:40:47,940 : INFO : PROGRESS: at sentence #40000, processed 315568 words, keeping 27424 word types\n",
      "2018-12-28 10:40:47,960 : INFO : PROGRESS: at sentence #50000, processed 393975 words, keeping 31263 word types\n",
      "2018-12-28 10:40:47,981 : INFO : PROGRESS: at sentence #60000, processed 475293 words, keeping 34923 word types\n",
      "2018-12-28 10:40:48,003 : INFO : PROGRESS: at sentence #70000, processed 555039 words, keeping 38352 word types\n",
      "2018-12-28 10:40:48,024 : INFO : PROGRESS: at sentence #80000, processed 637946 words, keeping 41670 word types\n",
      "2018-12-28 10:40:48,046 : INFO : PROGRESS: at sentence #90000, processed 716858 words, keeping 44834 word types\n",
      "2018-12-28 10:40:48,067 : INFO : PROGRESS: at sentence #100000, processed 798211 words, keeping 47784 word types\n",
      "2018-12-28 10:40:48,094 : INFO : PROGRESS: at sentence #110000, processed 886521 words, keeping 50733 word types\n",
      "2018-12-28 10:40:48,115 : INFO : PROGRESS: at sentence #120000, processed 968088 words, keeping 53407 word types\n",
      "2018-12-28 10:40:48,138 : INFO : PROGRESS: at sentence #130000, processed 1054320 words, keeping 56085 word types\n",
      "2018-12-28 10:40:48,161 : INFO : PROGRESS: at sentence #140000, processed 1142565 words, keeping 58685 word types\n",
      "2018-12-28 10:40:48,184 : INFO : PROGRESS: at sentence #150000, processed 1236163 words, keeping 61163 word types\n",
      "2018-12-28 10:40:48,217 : INFO : PROGRESS: at sentence #160000, processed 1329353 words, keeping 63652 word types\n",
      "2018-12-28 10:40:48,242 : INFO : PROGRESS: at sentence #170000, processed 1422623 words, keeping 66004 word types\n",
      "2018-12-28 10:40:48,266 : INFO : PROGRESS: at sentence #180000, processed 1519244 words, keeping 68068 word types\n",
      "2018-12-28 10:40:48,288 : INFO : PROGRESS: at sentence #190000, processed 1605117 words, keeping 69996 word types\n",
      "2018-12-28 10:40:48,309 : INFO : PROGRESS: at sentence #200000, processed 1684090 words, keeping 72033 word types\n",
      "2018-12-28 10:40:48,331 : INFO : PROGRESS: at sentence #210000, processed 1770738 words, keeping 74169 word types\n",
      "2018-12-28 10:40:48,354 : INFO : PROGRESS: at sentence #220000, processed 1855620 words, keeping 76547 word types\n",
      "2018-12-28 10:40:48,376 : INFO : PROGRESS: at sentence #230000, processed 1939232 words, keeping 78218 word types\n",
      "2018-12-28 10:40:48,399 : INFO : PROGRESS: at sentence #240000, processed 2026950 words, keeping 80004 word types\n",
      "2018-12-28 10:40:48,426 : INFO : PROGRESS: at sentence #250000, processed 2111813 words, keeping 81765 word types\n",
      "2018-12-28 10:40:48,449 : INFO : PROGRESS: at sentence #260000, processed 2200501 words, keeping 83745 word types\n",
      "2018-12-28 10:40:48,471 : INFO : PROGRESS: at sentence #270000, processed 2287891 words, keeping 85242 word types\n",
      "2018-12-28 10:40:48,493 : INFO : PROGRESS: at sentence #280000, processed 2376278 words, keeping 86851 word types\n",
      "2018-12-28 10:40:48,518 : INFO : PROGRESS: at sentence #290000, processed 2466384 words, keeping 88479 word types\n",
      "2018-12-28 10:40:48,541 : INFO : PROGRESS: at sentence #300000, processed 2559720 words, keeping 90392 word types\n",
      "2018-12-28 10:40:48,565 : INFO : PROGRESS: at sentence #310000, processed 2656756 words, keeping 92228 word types\n",
      "2018-12-28 10:40:48,589 : INFO : PROGRESS: at sentence #320000, processed 2745892 words, keeping 93745 word types\n",
      "2018-12-28 10:40:48,617 : INFO : PROGRESS: at sentence #330000, processed 2831961 words, keeping 95149 word types\n",
      "2018-12-28 10:40:48,640 : INFO : PROGRESS: at sentence #340000, processed 2916031 words, keeping 96447 word types\n",
      "2018-12-28 10:40:48,670 : INFO : PROGRESS: at sentence #350000, processed 3002846 words, keeping 98447 word types\n",
      "2018-12-28 10:40:48,691 : INFO : PROGRESS: at sentence #360000, processed 3085814 words, keeping 99854 word types\n",
      "2018-12-28 10:40:48,715 : INFO : PROGRESS: at sentence #370000, processed 3172840 words, keeping 101334 word types\n",
      "2018-12-28 10:40:48,756 : INFO : PROGRESS: at sentence #380000, processed 3254886 words, keeping 102657 word types\n",
      "2018-12-28 10:40:48,786 : INFO : PROGRESS: at sentence #390000, processed 3343703 words, keeping 104095 word types\n",
      "2018-12-28 10:40:48,815 : INFO : PROGRESS: at sentence #400000, processed 3428094 words, keeping 105424 word types\n",
      "2018-12-28 10:40:48,845 : INFO : PROGRESS: at sentence #410000, processed 3517225 words, keeping 107020 word types\n",
      "2018-12-28 10:40:48,875 : INFO : PROGRESS: at sentence #420000, processed 3612309 words, keeping 108651 word types\n",
      "2018-12-28 10:40:48,904 : INFO : PROGRESS: at sentence #430000, processed 3698310 words, keeping 109819 word types\n",
      "2018-12-28 10:40:48,932 : INFO : PROGRESS: at sentence #440000, processed 3789438 words, keeping 111045 word types\n",
      "2018-12-28 10:40:48,963 : INFO : PROGRESS: at sentence #450000, processed 3895596 words, keeping 112492 word types\n",
      "2018-12-28 10:40:48,991 : INFO : PROGRESS: at sentence #460000, processed 3984716 words, keeping 113697 word types\n",
      "2018-12-28 10:40:49,019 : INFO : PROGRESS: at sentence #470000, processed 4073682 words, keeping 115057 word types\n",
      "2018-12-28 10:40:49,063 : INFO : PROGRESS: at sentence #480000, processed 4166858 words, keeping 116502 word types\n",
      "2018-12-28 10:40:49,096 : INFO : PROGRESS: at sentence #490000, processed 4244927 words, keeping 117533 word types\n",
      "2018-12-28 10:40:49,125 : INFO : PROGRESS: at sentence #500000, processed 4324829 words, keeping 118602 word types\n",
      "2018-12-28 10:40:49,153 : INFO : PROGRESS: at sentence #510000, processed 4408183 words, keeping 119852 word types\n",
      "2018-12-28 10:40:49,179 : INFO : PROGRESS: at sentence #520000, processed 4484927 words, keeping 120746 word types\n",
      "2018-12-28 10:40:49,206 : INFO : PROGRESS: at sentence #530000, processed 4567866 words, keeping 121827 word types\n",
      "2018-12-28 10:40:49,233 : INFO : PROGRESS: at sentence #540000, processed 4651944 words, keeping 123153 word types\n",
      "2018-12-28 10:40:49,260 : INFO : PROGRESS: at sentence #550000, processed 4736303 words, keeping 124270 word types\n",
      "2018-12-28 10:40:49,285 : INFO : PROGRESS: at sentence #560000, processed 4817342 words, keeping 125236 word types\n",
      "2018-12-28 10:40:49,312 : INFO : PROGRESS: at sentence #570000, processed 4905694 words, keeping 126338 word types\n",
      "2018-12-28 10:40:49,337 : INFO : PROGRESS: at sentence #580000, processed 4987978 words, keeping 127529 word types\n",
      "2018-12-28 10:40:49,378 : INFO : PROGRESS: at sentence #590000, processed 5084477 words, keeping 129144 word types\n",
      "2018-12-28 10:40:49,411 : INFO : PROGRESS: at sentence #600000, processed 5172306 words, keeping 130434 word types\n",
      "2018-12-28 10:40:49,436 : INFO : PROGRESS: at sentence #610000, processed 5256833 words, keeping 131516 word types\n",
      "2018-12-28 10:40:49,463 : INFO : PROGRESS: at sentence #620000, processed 5347463 words, keeping 132726 word types\n",
      "2018-12-28 10:40:49,489 : INFO : PROGRESS: at sentence #630000, processed 5435227 words, keeping 133759 word types\n",
      "2018-12-28 10:40:49,513 : INFO : PROGRESS: at sentence #640000, processed 5517144 words, keeping 134803 word types\n",
      "2018-12-28 10:40:49,544 : INFO : PROGRESS: at sentence #650000, processed 5624202 words, keeping 136565 word types\n",
      "2018-12-28 10:40:49,575 : INFO : PROGRESS: at sentence #660000, processed 5727340 words, keeping 138455 word types\n",
      "2018-12-28 10:40:49,605 : INFO : PROGRESS: at sentence #670000, processed 5834068 words, keeping 140069 word types\n",
      "2018-12-28 10:40:49,636 : INFO : PROGRESS: at sentence #680000, processed 5943358 words, keeping 141580 word types\n",
      "2018-12-28 10:40:49,663 : INFO : PROGRESS: at sentence #690000, processed 6039744 words, keeping 142832 word types\n",
      "2018-12-28 10:40:49,690 : INFO : PROGRESS: at sentence #700000, processed 6132640 words, keeping 144137 word types\n",
      "2018-12-28 10:40:49,715 : INFO : PROGRESS: at sentence #710000, processed 6222812 words, keeping 145270 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-28 10:40:49,741 : INFO : PROGRESS: at sentence #720000, processed 6314516 words, keeping 146283 word types\n",
      "2018-12-28 10:40:49,766 : INFO : PROGRESS: at sentence #730000, processed 6400415 words, keeping 147267 word types\n",
      "2018-12-28 10:40:49,790 : INFO : PROGRESS: at sentence #740000, processed 6481978 words, keeping 147967 word types\n",
      "2018-12-28 10:40:49,814 : INFO : PROGRESS: at sentence #750000, processed 6563882 words, keeping 148731 word types\n",
      "2018-12-28 10:40:49,840 : INFO : PROGRESS: at sentence #760000, processed 6653710 words, keeping 149832 word types\n",
      "2018-12-28 10:40:49,866 : INFO : PROGRESS: at sentence #770000, processed 6746030 words, keeping 150828 word types\n",
      "2018-12-28 10:40:49,892 : INFO : PROGRESS: at sentence #780000, processed 6836710 words, keeping 151971 word types\n",
      "2018-12-28 10:40:49,916 : INFO : PROGRESS: at sentence #790000, processed 6919130 words, keeping 152878 word types\n",
      "2018-12-28 10:40:49,940 : INFO : PROGRESS: at sentence #800000, processed 7002758 words, keeping 153746 word types\n",
      "2018-12-28 10:40:49,964 : INFO : PROGRESS: at sentence #810000, processed 7084104 words, keeping 154618 word types\n",
      "2018-12-28 10:40:49,989 : INFO : PROGRESS: at sentence #820000, processed 7169796 words, keeping 155424 word types\n",
      "2018-12-28 10:40:50,016 : INFO : PROGRESS: at sentence #830000, processed 7264439 words, keeping 156668 word types\n",
      "2018-12-28 10:40:50,040 : INFO : PROGRESS: at sentence #840000, processed 7350217 words, keeping 157572 word types\n",
      "2018-12-28 10:40:50,066 : INFO : PROGRESS: at sentence #850000, processed 7438562 words, keeping 158503 word types\n",
      "2018-12-28 10:40:50,092 : INFO : PROGRESS: at sentence #860000, processed 7532850 words, keeping 159513 word types\n",
      "2018-12-28 10:40:50,117 : INFO : PROGRESS: at sentence #870000, processed 7618931 words, keeping 160311 word types\n",
      "2018-12-28 10:40:50,142 : INFO : PROGRESS: at sentence #880000, processed 7708308 words, keeping 161141 word types\n",
      "2018-12-28 10:40:50,166 : INFO : PROGRESS: at sentence #890000, processed 7795636 words, keeping 161986 word types\n",
      "2018-12-28 10:40:50,192 : INFO : PROGRESS: at sentence #900000, processed 7885266 words, keeping 162898 word types\n",
      "2018-12-28 10:40:50,217 : INFO : PROGRESS: at sentence #910000, processed 7972579 words, keeping 163890 word types\n",
      "2018-12-28 10:40:50,240 : INFO : PROGRESS: at sentence #920000, processed 8053250 words, keeping 164567 word types\n",
      "2018-12-28 10:40:50,264 : INFO : PROGRESS: at sentence #930000, processed 8139345 words, keeping 165388 word types\n",
      "2018-12-28 10:40:50,288 : INFO : PROGRESS: at sentence #940000, processed 8222237 words, keeping 166122 word types\n",
      "2018-12-28 10:40:50,312 : INFO : PROGRESS: at sentence #950000, processed 8307195 words, keeping 166749 word types\n",
      "2018-12-28 10:40:50,337 : INFO : PROGRESS: at sentence #960000, processed 8393183 words, keeping 167715 word types\n",
      "2018-12-28 10:40:50,362 : INFO : PROGRESS: at sentence #970000, processed 8480592 words, keeping 168614 word types\n",
      "2018-12-28 10:40:50,386 : INFO : PROGRESS: at sentence #980000, processed 8564178 words, keeping 169514 word types\n",
      "2018-12-28 10:40:50,412 : INFO : PROGRESS: at sentence #990000, processed 8656000 words, keeping 170478 word types\n",
      "2018-12-28 10:40:50,435 : INFO : PROGRESS: at sentence #1000000, processed 8740024 words, keeping 171255 word types\n",
      "2018-12-28 10:40:50,459 : INFO : PROGRESS: at sentence #1010000, processed 8822864 words, keeping 172151 word types\n",
      "2018-12-28 10:40:50,485 : INFO : PROGRESS: at sentence #1020000, processed 8917171 words, keeping 173197 word types\n",
      "2018-12-28 10:40:50,510 : INFO : PROGRESS: at sentence #1030000, processed 9006701 words, keeping 174266 word types\n",
      "2018-12-28 10:40:50,542 : INFO : PROGRESS: at sentence #1040000, processed 9104944 words, keeping 175283 word types\n",
      "2018-12-28 10:40:50,568 : INFO : PROGRESS: at sentence #1050000, processed 9198047 words, keeping 176210 word types\n",
      "2018-12-28 10:40:50,592 : INFO : PROGRESS: at sentence #1060000, processed 9289146 words, keeping 177103 word types\n",
      "2018-12-28 10:40:50,618 : INFO : PROGRESS: at sentence #1070000, processed 9379483 words, keeping 177983 word types\n",
      "2018-12-28 10:40:50,643 : INFO : PROGRESS: at sentence #1080000, processed 9471860 words, keeping 178845 word types\n",
      "2018-12-28 10:40:50,669 : INFO : PROGRESS: at sentence #1090000, processed 9565764 words, keeping 179695 word types\n",
      "2018-12-28 10:40:50,696 : INFO : PROGRESS: at sentence #1100000, processed 9657072 words, keeping 180739 word types\n",
      "2018-12-28 10:40:50,720 : INFO : PROGRESS: at sentence #1110000, processed 9742297 words, keeping 181508 word types\n",
      "2018-12-28 10:40:50,744 : INFO : PROGRESS: at sentence #1120000, processed 9824392 words, keeping 182233 word types\n",
      "2018-12-28 10:40:50,769 : INFO : PROGRESS: at sentence #1130000, processed 9913197 words, keeping 182985 word types\n",
      "2018-12-28 10:40:50,793 : INFO : PROGRESS: at sentence #1140000, processed 9997389 words, keeping 183733 word types\n",
      "2018-12-28 10:40:50,817 : INFO : PROGRESS: at sentence #1150000, processed 10083381 words, keeping 184562 word types\n",
      "2018-12-28 10:40:50,843 : INFO : PROGRESS: at sentence #1160000, processed 10175534 words, keeping 185455 word types\n",
      "2018-12-28 10:40:50,867 : INFO : PROGRESS: at sentence #1170000, processed 10261020 words, keeping 186275 word types\n",
      "2018-12-28 10:40:50,895 : INFO : PROGRESS: at sentence #1180000, processed 10359564 words, keeping 187334 word types\n",
      "2018-12-28 10:40:50,920 : INFO : PROGRESS: at sentence #1190000, processed 10448029 words, keeping 188347 word types\n",
      "2018-12-28 10:40:50,944 : INFO : PROGRESS: at sentence #1200000, processed 10531662 words, keeping 189407 word types\n",
      "2018-12-28 10:40:50,967 : INFO : PROGRESS: at sentence #1210000, processed 10611198 words, keeping 190106 word types\n",
      "2018-12-28 10:40:50,991 : INFO : PROGRESS: at sentence #1220000, processed 10695347 words, keeping 190774 word types\n",
      "2018-12-28 10:40:51,015 : INFO : PROGRESS: at sentence #1230000, processed 10782358 words, keeping 191517 word types\n",
      "2018-12-28 10:40:51,039 : INFO : PROGRESS: at sentence #1240000, processed 10864053 words, keeping 192189 word types\n",
      "2018-12-28 10:40:51,065 : INFO : PROGRESS: at sentence #1250000, processed 10954671 words, keeping 193011 word types\n",
      "2018-12-28 10:40:51,088 : INFO : PROGRESS: at sentence #1260000, processed 11038623 words, keeping 193631 word types\n",
      "2018-12-28 10:40:51,110 : INFO : PROGRESS: at sentence #1270000, processed 11124481 words, keeping 194286 word types\n",
      "2018-12-28 10:40:51,134 : INFO : PROGRESS: at sentence #1280000, processed 11223709 words, keeping 195496 word types\n",
      "2018-12-28 10:40:51,157 : INFO : PROGRESS: at sentence #1290000, processed 11318861 words, keeping 196330 word types\n",
      "2018-12-28 10:40:51,180 : INFO : PROGRESS: at sentence #1300000, processed 11416855 words, keeping 197051 word types\n",
      "2018-12-28 10:40:51,201 : INFO : PROGRESS: at sentence #1310000, processed 11503710 words, keeping 197732 word types\n",
      "2018-12-28 10:40:51,221 : INFO : PROGRESS: at sentence #1320000, processed 11586149 words, keeping 198543 word types\n",
      "2018-12-28 10:40:51,244 : INFO : PROGRESS: at sentence #1330000, processed 11676781 words, keeping 199447 word types\n",
      "2018-12-28 10:40:51,264 : INFO : PROGRESS: at sentence #1340000, processed 11760985 words, keeping 200226 word types\n",
      "2018-12-28 10:40:51,284 : INFO : PROGRESS: at sentence #1350000, processed 11841638 words, keeping 200835 word types\n",
      "2018-12-28 10:40:51,304 : INFO : PROGRESS: at sentence #1360000, processed 11923281 words, keeping 201483 word types\n",
      "2018-12-28 10:40:51,324 : INFO : PROGRESS: at sentence #1370000, processed 12008613 words, keeping 202123 word types\n",
      "2018-12-28 10:40:51,345 : INFO : PROGRESS: at sentence #1380000, processed 12094940 words, keeping 202738 word types\n",
      "2018-12-28 10:40:51,365 : INFO : PROGRESS: at sentence #1390000, processed 12178310 words, keeping 203392 word types\n",
      "2018-12-28 10:40:51,385 : INFO : PROGRESS: at sentence #1400000, processed 12262139 words, keeping 204017 word types\n",
      "2018-12-28 10:40:51,406 : INFO : PROGRESS: at sentence #1410000, processed 12349502 words, keeping 204664 word types\n",
      "2018-12-28 10:40:51,427 : INFO : PROGRESS: at sentence #1420000, processed 12440407 words, keeping 205378 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-28 10:40:51,448 : INFO : PROGRESS: at sentence #1430000, processed 12528254 words, keeping 206083 word types\n",
      "2018-12-28 10:40:51,472 : INFO : PROGRESS: at sentence #1440000, processed 12633920 words, keeping 206989 word types\n",
      "2018-12-28 10:40:51,499 : INFO : PROGRESS: at sentence #1450000, processed 12754387 words, keeping 208233 word types\n",
      "2018-12-28 10:40:51,525 : INFO : PROGRESS: at sentence #1460000, processed 12866569 words, keeping 209495 word types\n",
      "2018-12-28 10:40:51,544 : INFO : PROGRESS: at sentence #1470000, processed 12946117 words, keeping 210272 word types\n",
      "2018-12-28 10:40:51,564 : INFO : PROGRESS: at sentence #1480000, processed 13027589 words, keeping 210986 word types\n",
      "2018-12-28 10:40:51,584 : INFO : PROGRESS: at sentence #1490000, processed 13114794 words, keeping 211737 word types\n",
      "2018-12-28 10:40:51,603 : INFO : PROGRESS: at sentence #1500000, processed 13193264 words, keeping 212538 word types\n",
      "2018-12-28 10:40:51,626 : INFO : PROGRESS: at sentence #1510000, processed 13291228 words, keeping 213495 word types\n",
      "2018-12-28 10:40:51,645 : INFO : PROGRESS: at sentence #1520000, processed 13371910 words, keeping 214302 word types\n",
      "2018-12-28 10:40:51,666 : INFO : PROGRESS: at sentence #1530000, processed 13460030 words, keeping 215217 word types\n",
      "2018-12-28 10:40:51,687 : INFO : PROGRESS: at sentence #1540000, processed 13549264 words, keeping 216237 word types\n",
      "2018-12-28 10:40:51,708 : INFO : PROGRESS: at sentence #1550000, processed 13642727 words, keeping 217036 word types\n",
      "2018-12-28 10:40:51,728 : INFO : PROGRESS: at sentence #1560000, processed 13726912 words, keeping 217767 word types\n",
      "2018-12-28 10:40:51,749 : INFO : PROGRESS: at sentence #1570000, processed 13817650 words, keeping 218396 word types\n",
      "2018-12-28 10:40:51,770 : INFO : PROGRESS: at sentence #1580000, processed 13907831 words, keeping 219035 word types\n",
      "2018-12-28 10:40:51,791 : INFO : PROGRESS: at sentence #1590000, processed 13996052 words, keeping 219768 word types\n",
      "2018-12-28 10:40:51,811 : INFO : PROGRESS: at sentence #1600000, processed 14082385 words, keeping 220442 word types\n",
      "2018-12-28 10:40:51,834 : INFO : PROGRESS: at sentence #1610000, processed 14184551 words, keeping 221400 word types\n",
      "2018-12-28 10:40:51,854 : INFO : PROGRESS: at sentence #1620000, processed 14266100 words, keeping 222173 word types\n",
      "2018-12-28 10:40:51,873 : INFO : PROGRESS: at sentence #1630000, processed 14344417 words, keeping 222847 word types\n",
      "2018-12-28 10:40:51,893 : INFO : PROGRESS: at sentence #1640000, processed 14427706 words, keeping 223772 word types\n",
      "2018-12-28 10:40:51,914 : INFO : PROGRESS: at sentence #1650000, processed 14516078 words, keeping 224596 word types\n",
      "2018-12-28 10:40:51,936 : INFO : PROGRESS: at sentence #1660000, processed 14604289 words, keeping 225652 word types\n",
      "2018-12-28 10:40:51,957 : INFO : PROGRESS: at sentence #1670000, processed 14690209 words, keeping 226489 word types\n",
      "2018-12-28 10:40:51,978 : INFO : PROGRESS: at sentence #1680000, processed 14781839 words, keeping 227392 word types\n",
      "2018-12-28 10:40:51,998 : INFO : PROGRESS: at sentence #1690000, processed 14864769 words, keeping 228096 word types\n",
      "2018-12-28 10:40:52,021 : INFO : PROGRESS: at sentence #1700000, processed 14960978 words, keeping 229259 word types\n",
      "2018-12-28 10:40:52,043 : INFO : PROGRESS: at sentence #1710000, processed 15054701 words, keeping 230242 word types\n",
      "2018-12-28 10:40:52,066 : INFO : PROGRESS: at sentence #1720000, processed 15150331 words, keeping 231386 word types\n",
      "2018-12-28 10:40:52,091 : INFO : PROGRESS: at sentence #1730000, processed 15252510 words, keeping 232818 word types\n",
      "2018-12-28 10:40:52,113 : INFO : PROGRESS: at sentence #1740000, processed 15347181 words, keeping 233973 word types\n",
      "2018-12-28 10:40:52,135 : INFO : PROGRESS: at sentence #1750000, processed 15440506 words, keeping 234965 word types\n",
      "2018-12-28 10:40:52,156 : INFO : PROGRESS: at sentence #1760000, processed 15529160 words, keeping 235654 word types\n",
      "2018-12-28 10:40:52,178 : INFO : PROGRESS: at sentence #1770000, processed 15615890 words, keeping 236445 word types\n",
      "2018-12-28 10:40:52,199 : INFO : PROGRESS: at sentence #1780000, processed 15703224 words, keeping 237162 word types\n",
      "2018-12-28 10:40:52,218 : INFO : PROGRESS: at sentence #1790000, processed 15784445 words, keeping 237766 word types\n",
      "2018-12-28 10:40:52,238 : INFO : PROGRESS: at sentence #1800000, processed 15865324 words, keeping 238387 word types\n",
      "2018-12-28 10:40:52,257 : INFO : PROGRESS: at sentence #1810000, processed 15945018 words, keeping 238951 word types\n",
      "2018-12-28 10:40:52,276 : INFO : PROGRESS: at sentence #1820000, processed 16022050 words, keeping 239527 word types\n",
      "2018-12-28 10:40:52,295 : INFO : PROGRESS: at sentence #1830000, processed 16101474 words, keeping 240212 word types\n",
      "2018-12-28 10:40:52,315 : INFO : PROGRESS: at sentence #1840000, processed 16184640 words, keeping 240863 word types\n",
      "2018-12-28 10:40:52,335 : INFO : PROGRESS: at sentence #1850000, processed 16273130 words, keeping 241709 word types\n",
      "2018-12-28 10:40:52,356 : INFO : PROGRESS: at sentence #1860000, processed 16364708 words, keeping 242485 word types\n",
      "2018-12-28 10:40:52,375 : INFO : PROGRESS: at sentence #1870000, processed 16452528 words, keeping 243148 word types\n",
      "2018-12-28 10:40:52,394 : INFO : PROGRESS: at sentence #1880000, processed 16540013 words, keeping 243736 word types\n",
      "2018-12-28 10:40:52,415 : INFO : PROGRESS: at sentence #1890000, processed 16636137 words, keeping 244586 word types\n",
      "2018-12-28 10:40:52,435 : INFO : PROGRESS: at sentence #1900000, processed 16726233 words, keeping 245372 word types\n",
      "2018-12-28 10:40:52,454 : INFO : PROGRESS: at sentence #1910000, processed 16811951 words, keeping 246084 word types\n",
      "2018-12-28 10:40:52,472 : INFO : PROGRESS: at sentence #1920000, processed 16895542 words, keeping 246642 word types\n",
      "2018-12-28 10:40:52,492 : INFO : PROGRESS: at sentence #1930000, processed 16987574 words, keeping 247377 word types\n",
      "2018-12-28 10:40:52,511 : INFO : PROGRESS: at sentence #1940000, processed 17073694 words, keeping 248078 word types\n",
      "2018-12-28 10:40:52,530 : INFO : PROGRESS: at sentence #1950000, processed 17154916 words, keeping 248699 word types\n",
      "2018-12-28 10:40:52,549 : INFO : PROGRESS: at sentence #1960000, processed 17238136 words, keeping 249223 word types\n",
      "2018-12-28 10:40:52,568 : INFO : PROGRESS: at sentence #1970000, processed 17328669 words, keeping 249955 word types\n",
      "2018-12-28 10:40:52,588 : INFO : PROGRESS: at sentence #1980000, processed 17418382 words, keeping 250556 word types\n",
      "2018-12-28 10:40:52,608 : INFO : PROGRESS: at sentence #1990000, processed 17510231 words, keeping 251173 word types\n",
      "2018-12-28 10:40:52,627 : INFO : PROGRESS: at sentence #2000000, processed 17596452 words, keeping 251759 word types\n",
      "2018-12-28 10:40:52,646 : INFO : PROGRESS: at sentence #2010000, processed 17680257 words, keeping 252313 word types\n",
      "2018-12-28 10:40:52,664 : INFO : PROGRESS: at sentence #2020000, processed 17765286 words, keeping 252947 word types\n",
      "2018-12-28 10:40:52,683 : INFO : PROGRESS: at sentence #2030000, processed 17848999 words, keeping 253538 word types\n",
      "2018-12-28 10:40:52,702 : INFO : PROGRESS: at sentence #2040000, processed 17934973 words, keeping 254116 word types\n",
      "2018-12-28 10:40:52,721 : INFO : PROGRESS: at sentence #2050000, processed 18022325 words, keeping 254727 word types\n",
      "2018-12-28 10:40:52,741 : INFO : PROGRESS: at sentence #2060000, processed 18112679 words, keeping 255466 word types\n",
      "2018-12-28 10:40:52,761 : INFO : PROGRESS: at sentence #2070000, processed 18203750 words, keeping 256169 word types\n",
      "2018-12-28 10:40:52,779 : INFO : PROGRESS: at sentence #2080000, processed 18287008 words, keeping 256712 word types\n",
      "2018-12-28 10:40:52,799 : INFO : PROGRESS: at sentence #2090000, processed 18376933 words, keeping 257366 word types\n",
      "2018-12-28 10:40:52,818 : INFO : PROGRESS: at sentence #2100000, processed 18460384 words, keeping 258064 word types\n",
      "2018-12-28 10:40:52,838 : INFO : PROGRESS: at sentence #2110000, processed 18550691 words, keeping 258819 word types\n",
      "2018-12-28 10:40:52,857 : INFO : PROGRESS: at sentence #2120000, processed 18638247 words, keeping 259469 word types\n",
      "2018-12-28 10:40:52,877 : INFO : PROGRESS: at sentence #2130000, processed 18729634 words, keeping 260121 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-28 10:40:52,896 : INFO : PROGRESS: at sentence #2140000, processed 18816129 words, keeping 260949 word types\n",
      "2018-12-28 10:40:52,917 : INFO : PROGRESS: at sentence #2150000, processed 18912745 words, keeping 261785 word types\n",
      "2018-12-28 10:40:52,938 : INFO : PROGRESS: at sentence #2160000, processed 19011020 words, keeping 262628 word types\n",
      "2018-12-28 10:40:52,958 : INFO : PROGRESS: at sentence #2170000, processed 19106743 words, keeping 263462 word types\n",
      "2018-12-28 10:40:52,981 : INFO : PROGRESS: at sentence #2180000, processed 19217578 words, keeping 264242 word types\n",
      "2018-12-28 10:40:53,001 : INFO : PROGRESS: at sentence #2190000, processed 19304720 words, keeping 265084 word types\n",
      "2018-12-28 10:40:53,018 : INFO : collected 265647 word types from a corpus of 19384617 raw words and 2198991 sentences\n",
      "2018-12-28 10:40:53,019 : INFO : Loading a fresh vocabulary\n",
      "2018-12-28 10:40:53,298 : INFO : effective_min_count=5 retains 70592 unique words (26% of original 265647, drops 195055)\n",
      "2018-12-28 10:40:53,299 : INFO : effective_min_count=5 leaves 19086887 word corpus (98% of original 19384617, drops 297730)\n",
      "2018-12-28 10:40:53,465 : INFO : deleting the raw counts dictionary of 265647 items\n",
      "2018-12-28 10:40:53,473 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2018-12-28 10:40:53,474 : INFO : downsampling leaves estimated 16740960 word corpus (87.7% of prior 19086887)\n",
      "2018-12-28 10:40:53,643 : INFO : estimated required memory for 70592 words and 200 dimensions: 148243200 bytes\n",
      "2018-12-28 10:40:53,644 : INFO : resetting layer weights\n",
      "2018-12-28 10:40:54,344 : INFO : training model with 20 workers on 70592 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-12-28 10:40:55,409 : INFO : EPOCH 1 - PROGRESS: at 3.48% examples, 492129 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:40:56,431 : INFO : EPOCH 1 - PROGRESS: at 7.81% examples, 593079 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:40:57,454 : INFO : EPOCH 1 - PROGRESS: at 12.24% examples, 632519 words/s, in_qsize 40, out_qsize 1\n",
      "2018-12-28 10:40:58,463 : INFO : EPOCH 1 - PROGRESS: at 16.60% examples, 655770 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:40:59,472 : INFO : EPOCH 1 - PROGRESS: at 21.05% examples, 675104 words/s, in_qsize 40, out_qsize 0\n",
      "2018-12-28 10:41:00,492 : INFO : EPOCH 1 - PROGRESS: at 25.51% examples, 678815 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:01,495 : INFO : EPOCH 1 - PROGRESS: at 29.64% examples, 682483 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:02,503 : INFO : EPOCH 1 - PROGRESS: at 33.35% examples, 681118 words/s, in_qsize 40, out_qsize 1\n",
      "2018-12-28 10:41:03,526 : INFO : EPOCH 1 - PROGRESS: at 37.91% examples, 687001 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:04,564 : INFO : EPOCH 1 - PROGRESS: at 42.22% examples, 687553 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:05,565 : INFO : EPOCH 1 - PROGRESS: at 46.77% examples, 693431 words/s, in_qsize 40, out_qsize 0\n",
      "2018-12-28 10:41:06,566 : INFO : EPOCH 1 - PROGRESS: at 50.87% examples, 694601 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:07,571 : INFO : EPOCH 1 - PROGRESS: at 55.26% examples, 696805 words/s, in_qsize 40, out_qsize 0\n",
      "2018-12-28 10:41:08,578 : INFO : EPOCH 1 - PROGRESS: at 59.36% examples, 697024 words/s, in_qsize 40, out_qsize 0\n",
      "2018-12-28 10:41:09,610 : INFO : EPOCH 1 - PROGRESS: at 63.97% examples, 698770 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:10,617 : INFO : EPOCH 1 - PROGRESS: at 68.38% examples, 703604 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:11,619 : INFO : EPOCH 1 - PROGRESS: at 72.74% examples, 705288 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:12,644 : INFO : EPOCH 1 - PROGRESS: at 77.21% examples, 706129 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:13,648 : INFO : EPOCH 1 - PROGRESS: at 81.72% examples, 709327 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:14,671 : INFO : EPOCH 1 - PROGRESS: at 86.08% examples, 708459 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:15,674 : INFO : EPOCH 1 - PROGRESS: at 90.53% examples, 710055 words/s, in_qsize 40, out_qsize 0\n",
      "2018-12-28 10:41:16,675 : INFO : EPOCH 1 - PROGRESS: at 94.91% examples, 710229 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:17,586 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2018-12-28 10:41:17,620 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2018-12-28 10:41:17,638 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2018-12-28 10:41:17,647 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2018-12-28 10:41:17,655 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2018-12-28 10:41:17,662 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2018-12-28 10:41:17,675 : INFO : EPOCH 1 - PROGRESS: at 99.36% examples, 713489 words/s, in_qsize 13, out_qsize 1\n",
      "2018-12-28 10:41:17,678 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2018-12-28 10:41:17,694 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2018-12-28 10:41:17,701 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2018-12-28 10:41:17,702 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2018-12-28 10:41:17,704 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-12-28 10:41:17,706 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-12-28 10:41:17,709 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-12-28 10:41:17,714 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-12-28 10:41:17,717 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-12-28 10:41:17,721 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-12-28 10:41:17,723 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-12-28 10:41:17,726 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-28 10:41:17,730 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-28 10:41:17,732 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-28 10:41:17,733 : INFO : EPOCH - 1 : training on 19384617 raw words (16741378 effective words) took 23.4s, 716309 effective words/s\n",
      "2018-12-28 10:41:18,773 : INFO : EPOCH 2 - PROGRESS: at 4.22% examples, 610718 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:19,795 : INFO : EPOCH 2 - PROGRESS: at 8.84% examples, 684864 words/s, in_qsize 40, out_qsize 1\n",
      "2018-12-28 10:41:20,800 : INFO : EPOCH 2 - PROGRESS: at 13.39% examples, 706581 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:21,817 : INFO : EPOCH 2 - PROGRESS: at 17.70% examples, 705649 words/s, in_qsize 39, out_qsize 3\n",
      "2018-12-28 10:41:22,827 : INFO : EPOCH 2 - PROGRESS: at 22.18% examples, 717468 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:23,833 : INFO : EPOCH 2 - PROGRESS: at 26.71% examples, 716638 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:24,838 : INFO : EPOCH 2 - PROGRESS: at 30.43% examples, 708948 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:25,839 : INFO : EPOCH 2 - PROGRESS: at 34.66% examples, 712392 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:26,855 : INFO : EPOCH 2 - PROGRESS: at 38.99% examples, 711368 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:27,861 : INFO : EPOCH 2 - PROGRESS: at 43.72% examples, 717958 words/s, in_qsize 40, out_qsize 0\n",
      "2018-12-28 10:41:28,886 : INFO : EPOCH 2 - PROGRESS: at 48.13% examples, 719475 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:29,900 : INFO : EPOCH 2 - PROGRESS: at 52.75% examples, 723426 words/s, in_qsize 38, out_qsize 2\n",
      "2018-12-28 10:41:30,914 : INFO : EPOCH 2 - PROGRESS: at 57.48% examples, 727105 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:31,930 : INFO : EPOCH 2 - PROGRESS: at 61.51% examples, 723348 words/s, in_qsize 40, out_qsize 1\n",
      "2018-12-28 10:41:32,948 : INFO : EPOCH 2 - PROGRESS: at 65.96% examples, 726040 words/s, in_qsize 38, out_qsize 1\n",
      "2018-12-28 10:41:33,960 : INFO : EPOCH 2 - PROGRESS: at 70.36% examples, 725819 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:34,961 : INFO : EPOCH 2 - PROGRESS: at 74.77% examples, 726306 words/s, in_qsize 39, out_qsize 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-28 10:41:35,965 : INFO : EPOCH 2 - PROGRESS: at 79.11% examples, 727553 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:36,969 : INFO : EPOCH 2 - PROGRESS: at 83.80% examples, 728444 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:37,985 : INFO : EPOCH 2 - PROGRESS: at 88.17% examples, 728251 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:39,007 : INFO : EPOCH 2 - PROGRESS: at 92.67% examples, 728117 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:40,009 : INFO : EPOCH 2 - PROGRESS: at 97.12% examples, 728743 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:40,399 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2018-12-28 10:41:40,411 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2018-12-28 10:41:40,421 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2018-12-28 10:41:40,430 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2018-12-28 10:41:40,445 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2018-12-28 10:41:40,449 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2018-12-28 10:41:40,452 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2018-12-28 10:41:40,456 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2018-12-28 10:41:40,462 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2018-12-28 10:41:40,463 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2018-12-28 10:41:40,477 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-12-28 10:41:40,481 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-12-28 10:41:40,482 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-12-28 10:41:40,487 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-12-28 10:41:40,489 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-12-28 10:41:40,492 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-12-28 10:41:40,494 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-12-28 10:41:40,496 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-28 10:41:40,498 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-28 10:41:40,507 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-28 10:41:40,509 : INFO : EPOCH - 2 : training on 19384617 raw words (16742623 effective words) took 22.8s, 735647 effective words/s\n",
      "2018-12-28 10:41:41,528 : INFO : EPOCH 3 - PROGRESS: at 3.93% examples, 580971 words/s, in_qsize 40, out_qsize 0\n",
      "2018-12-28 10:41:42,539 : INFO : EPOCH 3 - PROGRESS: at 8.19% examples, 643492 words/s, in_qsize 38, out_qsize 1\n",
      "2018-12-28 10:41:43,548 : INFO : EPOCH 3 - PROGRESS: at 12.94% examples, 686938 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:44,551 : INFO : EPOCH 3 - PROGRESS: at 17.08% examples, 686945 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:45,568 : INFO : EPOCH 3 - PROGRESS: at 21.28% examples, 692547 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:46,593 : INFO : EPOCH 3 - PROGRESS: at 25.57% examples, 686903 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:47,625 : INFO : EPOCH 3 - PROGRESS: at 30.05% examples, 696431 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:48,664 : INFO : EPOCH 3 - PROGRESS: at 34.42% examples, 702427 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:49,673 : INFO : EPOCH 3 - PROGRESS: at 38.84% examples, 704932 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:50,683 : INFO : EPOCH 3 - PROGRESS: at 43.35% examples, 708378 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:51,697 : INFO : EPOCH 3 - PROGRESS: at 47.99% examples, 714625 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:52,706 : INFO : EPOCH 3 - PROGRESS: at 52.49% examples, 717820 words/s, in_qsize 40, out_qsize 1\n",
      "2018-12-28 10:41:53,706 : INFO : EPOCH 3 - PROGRESS: at 56.91% examples, 718655 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:54,712 : INFO : EPOCH 3 - PROGRESS: at 61.29% examples, 720336 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:55,716 : INFO : EPOCH 3 - PROGRESS: at 65.78% examples, 723408 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:56,718 : INFO : EPOCH 3 - PROGRESS: at 70.24% examples, 725343 words/s, in_qsize 37, out_qsize 3\n",
      "2018-12-28 10:41:57,719 : INFO : EPOCH 3 - PROGRESS: at 74.66% examples, 725831 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:58,729 : INFO : EPOCH 3 - PROGRESS: at 79.00% examples, 726854 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:41:59,732 : INFO : EPOCH 3 - PROGRESS: at 83.54% examples, 726488 words/s, in_qsize 38, out_qsize 1\n",
      "2018-12-28 10:42:00,743 : INFO : EPOCH 3 - PROGRESS: at 88.15% examples, 728715 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:42:01,757 : INFO : EPOCH 3 - PROGRESS: at 92.63% examples, 728430 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:42:02,765 : INFO : EPOCH 3 - PROGRESS: at 97.38% examples, 731177 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:42:03,125 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2018-12-28 10:42:03,140 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2018-12-28 10:42:03,144 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2018-12-28 10:42:03,153 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2018-12-28 10:42:03,157 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2018-12-28 10:42:03,160 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2018-12-28 10:42:03,162 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2018-12-28 10:42:03,171 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2018-12-28 10:42:03,175 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2018-12-28 10:42:03,190 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2018-12-28 10:42:03,192 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-12-28 10:42:03,193 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-12-28 10:42:03,195 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-12-28 10:42:03,197 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-12-28 10:42:03,198 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-12-28 10:42:03,200 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-12-28 10:42:03,203 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-12-28 10:42:03,205 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-28 10:42:03,208 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-28 10:42:03,214 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-28 10:42:03,215 : INFO : EPOCH - 3 : training on 19384617 raw words (16739869 effective words) took 22.7s, 737740 effective words/s\n",
      "2018-12-28 10:42:04,249 : INFO : EPOCH 4 - PROGRESS: at 4.05% examples, 592537 words/s, in_qsize 38, out_qsize 1\n",
      "2018-12-28 10:42:05,280 : INFO : EPOCH 4 - PROGRESS: at 8.30% examples, 642983 words/s, in_qsize 40, out_qsize 3\n",
      "2018-12-28 10:42:06,295 : INFO : EPOCH 4 - PROGRESS: at 12.54% examples, 656747 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:42:07,322 : INFO : EPOCH 4 - PROGRESS: at 16.92% examples, 671020 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:42:08,330 : INFO : EPOCH 4 - PROGRESS: at 21.33% examples, 687814 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:42:09,337 : INFO : EPOCH 4 - PROGRESS: at 26.10% examples, 697641 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:42:10,346 : INFO : EPOCH 4 - PROGRESS: at 30.48% examples, 708085 words/s, in_qsize 40, out_qsize 1\n",
      "2018-12-28 10:42:11,353 : INFO : EPOCH 4 - PROGRESS: at 34.85% examples, 714239 words/s, in_qsize 39, out_qsize 1\n",
      "2018-12-28 10:42:12,361 : INFO : EPOCH 4 - PROGRESS: at 39.60% examples, 721247 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:42:13,363 : INFO : EPOCH 4 - PROGRESS: at 44.03% examples, 722035 words/s, in_qsize 40, out_qsize 0\n",
      "2018-12-28 10:42:14,366 : INFO : EPOCH 4 - PROGRESS: at 47.93% examples, 716811 words/s, in_qsize 39, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-28 10:42:15,390 : INFO : EPOCH 4 - PROGRESS: at 52.34% examples, 717471 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:42:16,401 : INFO : EPOCH 4 - PROGRESS: at 57.06% examples, 721718 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:42:17,420 : INFO : EPOCH 4 - PROGRESS: at 61.40% examples, 721865 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:42:18,427 : INFO : EPOCH 4 - PROGRESS: at 65.85% examples, 724658 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:42:19,433 : INFO : EPOCH 4 - PROGRESS: at 70.55% examples, 728506 words/s, in_qsize 40, out_qsize 1\n",
      "2018-12-28 10:42:20,453 : INFO : EPOCH 4 - PROGRESS: at 75.26% examples, 730983 words/s, in_qsize 40, out_qsize 2\n",
      "2018-12-28 10:42:21,458 : INFO : EPOCH 4 - PROGRESS: at 79.39% examples, 730008 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:42:22,482 : INFO : EPOCH 4 - PROGRESS: at 84.11% examples, 730109 words/s, in_qsize 40, out_qsize 0\n",
      "2018-12-28 10:42:23,482 : INFO : EPOCH 4 - PROGRESS: at 88.20% examples, 728246 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:42:24,491 : INFO : EPOCH 4 - PROGRESS: at 93.05% examples, 730988 words/s, in_qsize 39, out_qsize 1\n",
      "2018-12-28 10:42:25,496 : INFO : EPOCH 4 - PROGRESS: at 97.63% examples, 732960 words/s, in_qsize 40, out_qsize 0\n",
      "2018-12-28 10:42:25,767 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2018-12-28 10:42:25,777 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2018-12-28 10:42:25,786 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2018-12-28 10:42:25,809 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2018-12-28 10:42:25,821 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2018-12-28 10:42:25,826 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2018-12-28 10:42:25,827 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2018-12-28 10:42:25,830 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2018-12-28 10:42:25,830 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2018-12-28 10:42:25,849 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2018-12-28 10:42:25,858 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-12-28 10:42:25,859 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-12-28 10:42:25,862 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-12-28 10:42:25,868 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-12-28 10:42:25,876 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-12-28 10:42:25,880 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-12-28 10:42:25,881 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-12-28 10:42:25,883 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-28 10:42:25,884 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-28 10:42:25,887 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-28 10:42:25,888 : INFO : EPOCH - 4 : training on 19384617 raw words (16741134 effective words) took 22.7s, 739079 effective words/s\n",
      "2018-12-28 10:42:26,909 : INFO : EPOCH 5 - PROGRESS: at 3.82% examples, 563069 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:42:27,914 : INFO : EPOCH 5 - PROGRESS: at 8.14% examples, 640639 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:42:28,920 : INFO : EPOCH 5 - PROGRESS: at 12.50% examples, 663243 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:42:29,926 : INFO : EPOCH 5 - PROGRESS: at 16.81% examples, 677361 words/s, in_qsize 38, out_qsize 0\n",
      "2018-12-28 10:42:30,930 : INFO : EPOCH 5 - PROGRESS: at 20.93% examples, 683210 words/s, in_qsize 38, out_qsize 1\n",
      "2018-12-28 10:42:31,940 : INFO : EPOCH 5 - PROGRESS: at 25.46% examples, 688090 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:42:32,942 : INFO : EPOCH 5 - PROGRESS: at 29.71% examples, 692999 words/s, in_qsize 40, out_qsize 1\n",
      "2018-12-28 10:42:33,946 : INFO : EPOCH 5 - PROGRESS: at 34.00% examples, 702575 words/s, in_qsize 40, out_qsize 1\n",
      "2018-12-28 10:42:34,984 : INFO : EPOCH 5 - PROGRESS: at 38.44% examples, 702906 words/s, in_qsize 40, out_qsize 5\n",
      "2018-12-28 10:42:35,998 : INFO : EPOCH 5 - PROGRESS: at 43.40% examples, 713947 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:42:37,038 : INFO : EPOCH 5 - PROGRESS: at 47.97% examples, 717220 words/s, in_qsize 38, out_qsize 1\n",
      "2018-12-28 10:42:38,053 : INFO : EPOCH 5 - PROGRESS: at 52.64% examples, 721997 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:42:39,059 : INFO : EPOCH 5 - PROGRESS: at 57.23% examples, 724169 words/s, in_qsize 40, out_qsize 0\n",
      "2018-12-28 10:42:40,069 : INFO : EPOCH 5 - PROGRESS: at 61.95% examples, 728931 words/s, in_qsize 38, out_qsize 2\n",
      "2018-12-28 10:42:41,073 : INFO : EPOCH 5 - PROGRESS: at 66.27% examples, 731264 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:42:42,106 : INFO : EPOCH 5 - PROGRESS: at 70.81% examples, 730804 words/s, in_qsize 37, out_qsize 2\n",
      "2018-12-28 10:42:43,128 : INFO : EPOCH 5 - PROGRESS: at 75.37% examples, 731579 words/s, in_qsize 39, out_qsize 0\n",
      "2018-12-28 10:42:44,137 : INFO : EPOCH 5 - PROGRESS: at 79.84% examples, 733716 words/s, in_qsize 40, out_qsize 0\n",
      "2018-12-28 10:42:45,141 : INFO : EPOCH 5 - PROGRESS: at 84.66% examples, 735301 words/s, in_qsize 40, out_qsize 1\n",
      "2018-12-28 10:42:46,163 : INFO : EPOCH 5 - PROGRESS: at 89.09% examples, 734581 words/s, in_qsize 40, out_qsize 0\n",
      "2018-12-28 10:42:47,188 : INFO : EPOCH 5 - PROGRESS: at 93.86% examples, 736380 words/s, in_qsize 38, out_qsize 1\n",
      "2018-12-28 10:42:48,192 : INFO : EPOCH 5 - PROGRESS: at 98.69% examples, 740477 words/s, in_qsize 26, out_qsize 2\n",
      "2018-12-28 10:42:48,249 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2018-12-28 10:42:48,257 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2018-12-28 10:42:48,275 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2018-12-28 10:42:48,290 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2018-12-28 10:42:48,313 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2018-12-28 10:42:48,324 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2018-12-28 10:42:48,337 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2018-12-28 10:42:48,349 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2018-12-28 10:42:48,353 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2018-12-28 10:42:48,357 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2018-12-28 10:42:48,360 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-12-28 10:42:48,363 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-12-28 10:42:48,364 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-12-28 10:42:48,365 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-12-28 10:42:48,377 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-12-28 10:42:48,378 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-12-28 10:42:48,383 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-12-28 10:42:48,388 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-12-28 10:42:48,389 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-12-28 10:42:48,394 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-12-28 10:42:48,395 : INFO : EPOCH - 5 : training on 19384617 raw words (16739349 effective words) took 22.5s, 744292 effective words/s\n",
      "2018-12-28 10:42:48,396 : INFO : training on a 96923085 raw words (83704353 effective words) took 114.1s, 733920 effective words/s\n",
      "2018-12-28 10:42:48,398 : INFO : saving Word2Vec object under ./word2vec/word2vec.model, separately None\n",
      "2018-12-28 10:42:48,399 : INFO : storing np array 'vectors' to ./word2vec/word2vec.model.wv.vectors.npy\n",
      "2018-12-28 10:42:48,483 : INFO : not storing attribute vectors_norm\n",
      "2018-12-28 10:42:48,486 : INFO : storing np array 'syn1neg' to ./word2vec/word2vec.model.trainables.syn1neg.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-28 10:42:48,535 : INFO : not storing attribute cum_table\n",
      "2018-12-28 10:42:48,682 : INFO : saved ./word2vec/word2vec.model\n"
     ]
    }
   ],
   "source": [
    "train_word2vec()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用来把分完词的句子向量化的函数\n",
    "def vec_lize(ls):\n",
    "    newls = []\n",
    "    for words in ls:\n",
    "        templs = []\n",
    "        for word in words:\n",
    "            try:\n",
    "                templs.append(model[word])\n",
    "            except:\n",
    "                pass\n",
    "        newls.append(templs)\n",
    "    return newls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 标签样本向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-28 10:47:31,682 : INFO : loading Word2Vec object from ./word2vec/word2vec.model\n",
      "2018-12-28 10:47:31,803 : INFO : loading wv recursively from ./word2vec/word2vec.model.wv.* with mmap=None\n",
      "2018-12-28 10:47:31,804 : INFO : loading vectors from ./word2vec/word2vec.model.wv.vectors.npy with mmap=None\n",
      "2018-12-28 10:47:31,844 : INFO : setting ignored attribute vectors_norm to None\n",
      "2018-12-28 10:47:31,845 : INFO : loading vocabulary recursively from ./word2vec/word2vec.model.vocabulary.* with mmap=None\n",
      "2018-12-28 10:47:31,846 : INFO : loading trainables recursively from ./word2vec/word2vec.model.trainables.* with mmap=None\n",
      "2018-12-28 10:47:31,847 : INFO : loading syn1neg from ./word2vec/word2vec.model.trainables.syn1neg.npy with mmap=None\n",
      "2018-12-28 10:47:31,879 : INFO : setting ignored attribute cum_table to None\n",
      "2018-12-28 10:47:31,880 : INFO : loaded ./word2vec/word2vec.model\n",
      "/opt/tljh/user/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec.load('./word2vec/word2vec.model')\n",
    "##随机打乱，为后续分训练，测试，验证集做准备\n",
    "df_shuffled = df_train_data.sample(frac = 1)\n",
    "##分出训练集，测试集，验证集\n",
    "a = len(df_train_data)\n",
    "xunlian = list(df_shuffled.iloc[0:int(a*0.8)].content)\n",
    "xunlian_label = list(df_shuffled.iloc[0:int(a*0.8)].label)\n",
    "ceshi = list(df_shuffled.iloc[int(a*0.8):int(a*0.9)].content)\n",
    "ceshi_label = list(df_shuffled.iloc[int(a*0.8):int(a*0.9)].label)\n",
    "yanzheng = list(df_shuffled.iloc[int(a*0.9):a].content)\n",
    "yanzheng_label = list(df_shuffled.iloc[int(a*0.9):a].label)\n",
    "##向量化\n",
    "xunlian = vec_lize(xunlian)\n",
    "ceshi = vec_lize(ceshi)\n",
    "yanzheng = vec_lize(yanzheng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deeplearning():\n",
    "    #参数设定\n",
    "    BATCH_SIZE = 100   #每次训练多少句话\n",
    "    TIME_STEPS = 30   #一句话多少个词向量\n",
    "    INPUT_SIZE = 200   #每个词向量的长度\n",
    "    OUTPUT_SIZE = 4  #label的宽度\n",
    "    LR = 0.001\n",
    "\n",
    "    #样本标签one hot 化\n",
    "    y_train = np_utils.to_categorical(xunlian_label, num_classes = OUTPUT_SIZE)\n",
    "    y_test = np_utils.to_categorical(ceshi_label, num_classes = OUTPUT_SIZE)\n",
    "    y_validation =  np_utils.to_categorical(yanzheng_label, num_classes = OUTPUT_SIZE)\n",
    "\n",
    "    #统一词向量长度\n",
    "    x_train = pad_sequences(xunlian, maxlen = TIME_STEPS, padding ='post', dtype = 'float')\n",
    "    x_test = pad_sequences(ceshi, maxlen = TIME_STEPS, padding ='post', dtype = 'float')\n",
    "    x_validation = pad_sequences(yanzheng, maxlen = TIME_STEPS, padding ='post', dtype = 'float')\n",
    "\n",
    "    #模型构建\n",
    "    #我试了RNN，LSTM，GRU发现GRU的效果相对比较好\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value = 0,input_shape = (TIME_STEPS,INPUT_SIZE)))#这里mask_value参数去除了输入的词向量中的零向量实现了GRU的变长度输入\n",
    "    model.add(Bidirectional(GRU(64)))#这里可选的参数常见有32,64,128,256我试了以后发现32比较好\n",
    "    model.add(Dropout(0.5))#这是对GRU门的设置，为了防止过拟合\n",
    "    model.add(Dense(OUTPUT_SIZE))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    adam = Adam(LR)\n",
    "    model.compile(optimizer = adam, \n",
    "                  loss = 'categorical_crossentropy', \n",
    "                  metrics = ['accuracy'])\n",
    "\n",
    "    #跑模型\n",
    "    result = model.fit(x_train,y_train, batch_size=BATCH_SIZE,\n",
    "                       nb_epoch=5, verbose=1, validation_data=(x_test, y_test))\n",
    "    \n",
    "    #评估\n",
    "    score, acc = model.evaluate(x_validation, y_validation, batch_size = BATCH_SIZE, verbose = 1)\n",
    "    print('五分类下的准确率{}'.format(acc))\n",
    "\n",
    "    # 鉴于上述四分的时候准确率不高，我们来看一下二分的时候\n",
    "    validation_label = model.predict_classes(x_validation,batch_size = BATCH_SIZE)\n",
    "    num = 0\n",
    "    for i in range(len(x_validation)):\n",
    "        if validation_label[i] <= 1 and yanzheng_label[i] <= 1:\n",
    "            num +=1\n",
    "        if validation_label[i] >=2 and yanzheng_label[i]>=2:\n",
    "            num+=1\n",
    "    print('二分法下的准确率{}'.format(num/len(x_validation)))#四分类不是很准，但是对市场情绪的积极，消极判断还是不错的\n",
    "\n",
    "    model.save('./GRU/gru.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获得预测样本情绪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_construction():\n",
    "    #导入模型，获得预测样本的情感标签\n",
    "    model = load_model('./GRU/gru.h5')\n",
    "    TIME_STEPS = 30\n",
    "    x_predict = pad_sequences(predict, maxlen = TIME_STEPS, padding ='post', dtype = 'float')\n",
    "    predict_label = model.predict_classes(x_predict)\n",
    "    df_predict_data['label'] = predict_label\n",
    "    #因为在做情感标记的时候为了onehot化方便，把情感从0开始标记。\n",
    "    #这里我们要更改标记为-2,-1,0,1,2\n",
    "    df_predict_data.label = df_predict_data.label.apply(lambda x: x-2 if x<=1 else x-1)\n",
    "    #获得每日的情感分数\n",
    "    df_final = df_predict_data.groupby('date').label.sum().to_frame()\n",
    "    #每日情感分数除每日收集的评论总数\n",
    "    df_count = df_predict_data.groupby('date').label.count()\n",
    "    df_final.label = df_final.label/df_count\n",
    "    #标准化\n",
    "    av = df_final.label.mean()\n",
    "    std = math.sqrt(df_final.label.std())\n",
    "    df_final.label = df_final.label.apply(lambda x: (x-av)/std)\n",
    "    df_final = df_final.loc['2016-08-31':'2018-12-01']\n",
    "    with open('final_data/'+ 'emotion_data' + '.pkl', 'wb') as f:\n",
    "        pickle.dump(df_final, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/tljh/user/lib/python3.6/site-packages/ipykernel_launcher.py:42: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 77204 samples, validate on 9651 samples\n",
      "Epoch 1/5\n",
      "77204/77204 [==============================] - 54s 697us/step - loss: 1.3256 - acc: 0.3900 - val_loss: 1.2725 - val_acc: 0.4170\n",
      "Epoch 2/5\n",
      "77204/77204 [==============================] - 51s 654us/step - loss: 1.2654 - acc: 0.4206 - val_loss: 1.2667 - val_acc: 0.4189\n",
      "Epoch 3/5\n",
      "77204/77204 [==============================] - 51s 663us/step - loss: 1.2528 - acc: 0.4262 - val_loss: 1.2681 - val_acc: 0.4200\n",
      "Epoch 4/5\n",
      "77204/77204 [==============================] - 51s 664us/step - loss: 1.2417 - acc: 0.4357 - val_loss: 1.2647 - val_acc: 0.4215\n",
      "Epoch 5/5\n",
      "77204/77204 [==============================] - 49s 641us/step - loss: 1.2287 - acc: 0.4452 - val_loss: 1.2691 - val_acc: 0.4172\n",
      "9651/9651 [==============================] - 3s 261us/step\n",
      "五分类下的准确率0.42689876530271975\n",
      "二分法下的准确率0.6330950160605119\n"
     ]
    }
   ],
   "source": [
    "deeplearning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 预测样本向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-28 10:52:17,881 : INFO : loading Word2Vec object from ./word2vec/word2vec.model\n",
      "2018-12-28 10:52:19,273 : INFO : loading wv recursively from ./word2vec/word2vec.model.wv.* with mmap=None\n",
      "2018-12-28 10:52:19,274 : INFO : loading vectors from ./word2vec/word2vec.model.wv.vectors.npy with mmap=None\n",
      "2018-12-28 10:52:19,306 : INFO : setting ignored attribute vectors_norm to None\n",
      "2018-12-28 10:52:19,307 : INFO : loading vocabulary recursively from ./word2vec/word2vec.model.vocabulary.* with mmap=None\n",
      "2018-12-28 10:52:19,308 : INFO : loading trainables recursively from ./word2vec/word2vec.model.trainables.* with mmap=None\n",
      "2018-12-28 10:52:19,309 : INFO : loading syn1neg from ./word2vec/word2vec.model.trainables.syn1neg.npy with mmap=None\n",
      "2018-12-28 10:52:19,340 : INFO : setting ignored attribute cum_table to None\n",
      "2018-12-28 10:52:19,341 : INFO : loaded ./word2vec/word2vec.model\n",
      "/opt/tljh/user/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#我发现如果这段写成函数，model老是莫名其妙报错，所以就没有写成函数了\n",
    "model = word2vec.Word2Vec.load('./word2vec/word2vec.model')\n",
    "predict = list(df_predict_data.content)\n",
    "predict = vec_lize(predict)#向量化后的文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_construction()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
