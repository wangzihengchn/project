{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import jieba\n",
    "import pickle\n",
    "import math\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用来存列表/字典的\n",
    "def save_obj(obj, name ):\n",
    "    with open('data/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "#用来读列表/字典的\n",
    "def load_obj(name ):\n",
    "    with open('data/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# 得到所选股票的股票代码存到 stock_name_list中\n",
    "def get_stock_name_list():\n",
    "    name = pd.read_table('stock_list.txt')\n",
    "    name['品种代码'] = name['品种代码'].apply(lambda x:x[0:-3])\n",
    "    stock_name_list = [i for i in name['品种代码']]\n",
    "    return stock_name_list\n",
    "stock_name_list = get_stock_name_list()\n",
    "\n",
    "#在分词以后，针对每一句话（列表形式）去除其中的数字，标点等\n",
    "filter_word = string.punctuation+string.ascii_letters+string.digits+'！？｡。＂＃＄％＆＇（）＊＋，－／：；＜＝＞＠［＼］＾＿｀｛｜｝～｟｠｢｣､、〃》「」『』【】〔〕〖〗〘〙〚〛〜〝〞〟〰〾〿–—‘’‛“”„‟…‧﹏.'\n",
    "def clean_predict_punc(ls):\n",
    "    new_ls = []\n",
    "    for i in ls:\n",
    "        if i not in filter_word:\n",
    "            try:\n",
    "                float(i)\n",
    "            except:\n",
    "                new_ls.append(i)\n",
    "    return new_ls\n",
    "\n",
    "#从之前存储评论的文件夹中获取评论\n",
    "def get_data(types):\n",
    "    df_all = pd.DataFrame(columns = ['date','content'])#一个空的DataFrame\n",
    "    for stock_code in stock_name_list:\n",
    "        newstore_predict_address = stock_code+'/'+stock_code+ types#构造地址,如000055/000055predict.pkl,如果types = predict\n",
    "        df = load_obj(newstore_predict_address)\n",
    "        df_all = df_all.append(df, ignore_index = True)#把这支股票的评论加到df_all里面，最后让df_all包含所有股票的带预测的评论\n",
    "    return df_all\n",
    "\n",
    "#分词函数(包括分词后的清理)\n",
    "def jieba_and_clean(df):\n",
    "    ##分词\n",
    "    df.content = df.content.apply(lambda x: list(jieba.cut(x)))#jieba分词并返回列表形式\n",
    "    ##清理\n",
    "    df.content = df.content.apply(lambda x: clean_predict_punc(x))#去除列表中的标点，数字等\n",
    "    df.content = df.content.astype(str)\n",
    "    df = df.loc[df.content != '[]']#去除空列表\n",
    "    df.content = df.content.apply(lambda x: eval(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测数据清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_data_dispose():\n",
    "    ##获取全部预测评论\n",
    "    df_predict = get_data('predict')\n",
    "    ##数据清理\n",
    "    df_predict = df_predict.sort_values(['date'], ascending = True)#将评论按时间排序\n",
    "    df_predict = df_predict[df_predict.date != '00']#去除缺失的评论（在爬虫中我把因为没抓下来的评论赋值成00）\n",
    "    df_predict = df_predict[df_predict.date >= '2016-08-31']#去除日期小于2016-08-31的评论\n",
    "    df_predict = df_predict.reindex(range(len(df_predict)))#因为评论按照时间排序了，index乱了，为了好看点重排index\n",
    "    ##分词和进一步清理\n",
    "    df_predict.content = df_predict.content.astype(str)#为了jieba分词做准备\n",
    "    df_predict = jieba_and_clean(df_predict)\n",
    "    ##储存\n",
    "    save_obj(df_predict, 'df_predict_data')#将处理完成的列表数据保存起来\n",
    "    #此处改为\n",
    "    #return df_predict\n",
    "    #就可以看到处理的结果了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 标签数据\n",
    "- expression_dict 得到每个表情对应的话\n",
    "- word_dict 得到每句话中包含的表情"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取表情符号\n",
    "def gain_expression_list():\n",
    "    df_train = get_data('train')\n",
    "    del df_train['date']\n",
    "    expression = {}\n",
    "    rdgx = re.compile('(\\[[^\\[\\]]*\\])')\n",
    "    for i in range(len(df_train)):\n",
    "        comment = df_train.iloc[i,0]\n",
    "        expr_ls = rdgx.findall(comment)\n",
    "        expr_ls = [x[1:-1] for x in expr_ls]\n",
    "        for i in expr_ls:\n",
    "            if i in expression:\n",
    "                expression[i] +=1\n",
    "            else:\n",
    "                expression[i] = 1\n",
    "    expression = sorted(expression.items(), key = lambda x:x[1], reverse = True)\n",
    "    expression = expression[0:41]\n",
    "    expression_list = []\n",
    "    for i in expression:\n",
    "        expression_list.append(i[0])\n",
    "    expression_list.remove('图片')\n",
    "    return expression_list,expression\n",
    "\n",
    "def train_data_dispose():\n",
    "    ##获取全部标签评论\n",
    "    df_train = get_data('train')\n",
    "    del df_train['date']#因为训练样本不需要日期，故删除\n",
    "    ##得到每句话包含的表情\n",
    "    for i in expression_list:\n",
    "        expression_dict[i] = []\n",
    "    word_dict = {}#用来存每句评论包含的表情符号，key = 评论，item = 包含表情（列表形式）\n",
    "    rdgx = re.compile('(\\[[^\\[\\]]*\\])')#用来匹配表情符号，如 [买入]\n",
    "    for i in range(len(df_train)):\n",
    "        comment = df_train.iloc[i,0]\n",
    "        expr_ls = rdgx.findall(comment)\n",
    "        expr_ls = [x[1:-1] for x in expr_ls]\n",
    "        comment= rdgx.sub('',comment)#去除comment中的表情符号\n",
    "        if comment !='':\n",
    "            if comment in word_dict:\n",
    "                pass#如果这句评论有了，就不加入了\n",
    "            else:\n",
    "                word_dict[comment] = expr_ls #向word_dict里面加东西，key = 评论，item = 包含表情（列表形式）\n",
    "            for i in set(expr_ls):\n",
    "                if i in expression_dict:\n",
    "                    expression_dict[i].append(comment)#向expression_dict里面加东西\n",
    "    ##储存\n",
    "    save_obj(expression_dict, 'expression_dict')\n",
    "    save_obj(word_dict,'word_dict')\n",
    "    ##返回\n",
    "    return expression_dict,word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.565 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "/opt/tljh/user/lib/python3.6/site-packages/pandas/core/generic.py:4405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "expression_list,expression = gain_expression_list()\n",
    "expression_dict = {}#用来存每个表情对应的评论\n",
    "predict_data_dispose()#这个函数跑得很慢\n",
    "expression_dict,word_dict = train_data_dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 确定每个表情的情感分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "尾盘没跑的，下周就累了\n",
      "跌停庆祝开业\n",
      "割肉喂鹰\n",
      "重点放在暴跌的中小创 最有潜力翻几倍！[\n",
      "真尼玛坚挺\n",
      "，早上卖万科错了[不\n",
      "早盘就该卖了\n",
      "冲啊\n",
      "总资金又增加六称了，你他妈还在原地打转……薛向东，你没治了\n",
      "放量大跌要开始了，下周都不要进入\n",
      "哎，上午22.15被洗出去了，不想说话\n",
      "没走的挂13.62卖\n",
      "这个冬天有点冷 ，寒风凛冽啊\n",
      "今天最弱也需要收在9.5之上。。加油吧，软蛋君！\n",
      "讯飞今天很衰的样子\n",
      "吧里真热闹，都是墙头草！\n",
      "这是要跌停的节奏啊\n",
      "好垃圾的股票\n",
      "机构左右手对倒，自卖自买，散户买不到。\n",
      "不怕死的快做接盘侠，\n",
      "活水魚才能不死呀……！\n",
      "你以为吃了一记九阴白骨爪就完了？没死的话，就再吃一记化骨绵掌\n",
      "真可怕。我怂了再见了 你们继续\n",
      "谁买谁死\n",
      "找不到那个说M头的傻币了\n",
      "很意外，今天华微不是跟着波导和中蒲联动上涨～居然自己拉了～搞什么鬼\n",
      "上例牌:低开，闷sha\n",
      "老夏说自己是最负责的企业家，没有之一！大家要相信他！\n",
      "变僵尸了\n",
      "半年报中，十大流通股东几个自然人是融资买入的\n",
      "这股看来是热了点震幅肯定也随厉害噢！小心山顶……。\n",
      "一个公司被玩得失去投资者信任，还谈什么价值投资\n",
      "周一大盘回调、这货借机通杀，手段残忍，祝大家好运了，这周！\n",
      "看看成交量，白痴都知道是诱多！\n",
      "新的一年开始了，多少进点钱，拉高点，再减持，双赢局面，就是不会，我无语\n",
      "谁能玩死这个庄我捐一百块！！！！\n",
      "跌的莫名其妙\n",
      "小四脉冲一下子就得歇一会儿啦 介TM战斗力完蛋玩意还\n",
      "002636:三季度加仓机构全部被套\n",
      "晕死，\n",
      "本来想在11.20多出掉，犹豫不决，现在又跌并傻逼了\n",
      "挣了6个点，跑了\n",
      "狗辣鸡\n",
      "你们闹去吧，反正我不动了，满仓了\n",
      "散户快走，博雅快来!\n",
      "看看成交量，白痴都知道是诱多！\n",
      "又打脸了\n",
      "这个位置还抛吗？难以理解这些股民\n",
      "被动式上涨 半推半就的被大盘拉扯的被动式上涨\n",
      "赶紧砸盘…………\n"
     ]
    }
   ],
   "source": [
    "##随机抽样（总共40个表情符号，每个表情符号各抽取50句评论人工打分）\n",
    "#此部分属于纯体力活，时间紧迫，抽取的评论比较少还请老师见谅，呜呜\n",
    "def sample_choose(expression_dict): \n",
    "    sample_dict = {}\n",
    "    for i in expression_dict:\n",
    "        sample_dict[i] = random.sample(expression_dict[i],50)\n",
    "    return sample_dict\n",
    "#这里举个例子，给带不说了这个表情打分\n",
    "sample = sample_choose(expression_dict)\n",
    "a = sample['不说了']\n",
    "for i in range(50):\n",
    "    print(a[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 打分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这里是根据一次抽样，我手工打上的标签，p积极，0中立，n消极\n",
    "\n",
    "a1 = '大笑   nnnppn0nppnnnpn0npnnpnn0000p0np00pn0pp00p00ppnn0pp'\n",
    "a2 = '献花   pppppppppppppppppppppnp00ppppppnp0pnpppppppppnpn00'\n",
    "a3 = '胜利   n0npnpppppnpp0000n00npppppnppppnn00pp000000nnppp00'\n",
    "a4 = '鼓掌   pn0nn000000000n0p00pp000p0p00ppppnppnppp0pnppp00n0'\n",
    "a5 = '微笑   pnnpnnnn000000ppppp0nppp000000np000000n000npnnnnn0'\n",
    "a6 = '哭     nnnnpppnnnnnnn0nn0nnnnn0nnpn0n0n0nnnnpnn0nnnpppnnn'\n",
    "a7 = '赞     00pn0npp0p0pp00n0pn00p000n0ppppn0n0pp0pnpnpp0npn00'\n",
    "a8 = '不赞   p00nn0nn00nnnn0nnn0nnnnnnnnnnn00nnn00nnnnnnnnnnn0n'\n",
    "a9 = '大便   0nnnn0n0nnnnnnnnnnnpnnnnnpnnnnn0nnnnnnnnn0nnnnn0pn'\n",
    "a10 = '买入  ppppppppppppppppp0pppppppp0ppppppp00ppppppnppnppnp'\n",
    "a11 = '不屑  00np0nnnnnnpn0nnnn0nnn00pnnnnn0pnnn0nppnnnnn00nnpn'\n",
    "a12 = '滴汗  np0n0nppp0000npnnnnnn0n0nnnnnn0nn0npnppnnnnnp000pp'\n",
    "a13 = '抄底  0n00pppp0np000ppp00p0ppppppp0000ppp0p0pp0ppnnp0pnp'\n",
    "a14 = '牛    0pppppppppppppppppp00p0ppppp0pppppp000pppp0p0ppppp'\n",
    "a15 = '摊手  ppppnpnnn0pnnn0n0npn0n00nnnnpnp0nnnnn0nnnnn0n00000'\n",
    "a16 = '拜神  p0p0p000pn000pppppp00nnppnn0nn0npppnppp00n00p0p0p0'\n",
    "a17 = '加油  p000pp0n0ppppn0pnnp0pp0p0n000np0ppnnnn000pp000nnnp'\n",
    "a18 = '加仓  ppp000pppppppppppppp0p00ppppppppp0p0ppppppppppppp0'\n",
    "a19 = '傲    00000nnnn0n0npn0nnp0p00n00nn000npnn0nnn0nnpnnnn0n0'\n",
    "a20 = '俏皮  npppp000000nnp0np0n0pppppp00000000pn0pnppn0ppppnpp'\n",
    "a21 = '卖出  nnnnnnnnnnnnnnnnnn0nn0nnnnnnnnnnnnnnnn0nnnnnnnnnnn'\n",
    "a22 = '怒    nnnnnnnnnnnnnnnnnnnnnnnnnnnnn0n0n0nnnnnnnnnnnnnnnn'\n",
    "a23 = '满仓  ppppppn0pppppppppppppppppppp0p0p0nppnp00nppppp0ppp'\n",
    "a24 = '兴奋  pp0p00nnpppnnn0nnnppnp00npnp0n0nnnppnnnnnp0pn0pppp'\n",
    "a25 = '心碎  0npnnnnnnnnnnnnnnnnnpnnnnnnnnnnnnnnnnnnnnnnnnnnnnn'\n",
    "a26 = '成交  np0ppp0n0nn0ppnnnnn00n00pn000nnnnnpnnnpn0000npn0np'\n",
    "a27 = '失望  nnnnnnnn00nnnnnnnnn00nnnn0nnnnnnnnnnn000nnnnnnnnnn'\n",
    "a28 = '围观  0000n00nnpnpp0nn000n0000000nnp0n0p00n000np0npnp0n0'\n",
    "a29 = '空仓  nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn'\n",
    "a30 = '困顿  0n0000nn0nn000000n000n000nnn0n0n0000n0n00000nn0nnn'\n",
    "a31 = '财力  ppppppppppp0ppppppppp0nnppp0ppppppppppn00pppnnpppp'\n",
    "a32 = '好逊  0n00nn0nn0n00nn0nn00n0n0npp000nnpnn0n0nnnnnnnnnnn0'\n",
    "a33 = '不说了00000nnnp00000000nnp0pn000n0n000ppnnn000p000000000'\n",
    "a34 = '看空  nnnnnnn0n0nnnnnnnn00n0nn0nnnn00nnnnnnnnnnnnnnn0000'\n",
    "a35 = '想一下nnp00npnn0n000n0nnnn0pnnn00nnp0n00n00ppnn00000p000'\n",
    "a36 = '亏大了np0pnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn'\n",
    "a37 = '为什么n000n00pp00000p00000000pn00nppp0n0pn000000n0pn00pp'\n",
    "a38 = '好困惑nnnp0nnnpnn0nnn0000000000n0n000000nn00nnn0nnn00npp'\n",
    "a39 = '赚大了pppppppppppppppppppppppppppppppppppppppppppppppppp'\n",
    "a40 = '看多  pppppppppppppppppppppppppppppppppppppppppppppppppp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对上面打的标签的结果进行一定的处理\n",
    "def expression_stat(ex):\n",
    "    expression = ex[0:3].rstrip(' ')#获取表情名称\n",
    "    expression_stats = ex[-1:-51:-1]\n",
    "    count_n = 0#数积极情绪的标签数\n",
    "    count_zero = 0#数中立情绪的标签数\n",
    "    count_p = 0#数消极情绪的标签数\n",
    "    trust = []\n",
    "    stat_ls = []\n",
    "    for i in expression_stats:\n",
    "        if i =='n':\n",
    "            count_n +=1\n",
    "        if i =='0':\n",
    "            count_zero +=1\n",
    "        if i =='p':\n",
    "            count_p +=1\n",
    "    #在这里我根据这个表情中积极情绪和消极情绪出现的次数作比较，将表情的极性分为积极和消极，\n",
    "    #分值按照： 积极情绪出现的次数/50   消极情绪出现的次数/50\n",
    "    if count_p>= count_n:\n",
    "        trust = [1,count_p/50]\n",
    "    else:\n",
    "        trust = [-1, count_n/50]\n",
    "    stat_ls = [count_n, count_zero, count_p]\n",
    "    stat_ls.extend(trust)\n",
    "    stat_ls.insert(0,expression)\n",
    "    return stat_ls\n",
    "\n",
    "def expression_mark():\n",
    "    ls_all = []\n",
    "    createvar = globals()#获取此时的全局变量（字典形式），这是一个非常重要的技巧\n",
    "    for i in range(1,41):\n",
    "        ls_all.append(expression_stat(createvar['a'+str(i)]))#从全局变量字典中取出变量\n",
    "    fm = '{}\\t{}\\t{}\\t{}\\t{}\\t{}'\n",
    "    print(fm.format('表情','积极个数','中立个数','消极个数','极性','分值'))\n",
    "    for i in ls_all:\n",
    "        print(fm.format(i[0],i[1],i[2],i[3],i[4],i[5]))\n",
    "    return ls_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "表情\t积极个数\t中立个数\t消极个数\t极性\t分值\n",
      "大笑\t18\t15\t17\t-1\t0.36\n",
      "献花\t5\t5\t40\t1\t0.8\n",
      "胜利\t11\t17\t22\t1\t0.44\n",
      "鼓掌\t8\t23\t19\t1\t0.38\n",
      "微笑\t15\t23\t12\t-1\t0.3\n",
      "哭\t35\t7\t8\t-1\t0.7\n",
      "赞\t11\t20\t19\t1\t0.38\n",
      "不赞\t37\t12\t1\t-1\t0.74\n",
      "大便\t41\t6\t3\t-1\t0.82\n",
      "买入\t3\t4\t43\t1\t0.86\n",
      "不屑\t32\t11\t7\t-1\t0.64\n",
      "滴汗\t26\t13\t11\t-1\t0.52\n",
      "抄底\t5\t18\t27\t1\t0.54\n",
      "牛\t0\t10\t40\t1\t0.8\n",
      "摊手\t27\t14\t9\t-1\t0.54\n",
      "拜神\t10\t19\t21\t1\t0.42\n",
      "加油\t13\t19\t18\t1\t0.36\n",
      "加仓\t0\t9\t41\t1\t0.82\n",
      "傲\t25\t20\t5\t-1\t0.5\n",
      "俏皮\t9\t19\t22\t1\t0.44\n",
      "卖出\t47\t3\t0\t-1\t0.94\n",
      "怒\t47\t3\t0\t-1\t0.94\n",
      "满仓\t4\t7\t39\t1\t0.78\n",
      "兴奋\t21\t10\t19\t-1\t0.42\n",
      "心碎\t47\t1\t2\t-1\t0.94\n",
      "成交\t23\t16\t11\t-1\t0.46\n",
      "失望\t42\t8\t0\t-1\t0.84\n",
      "围观\t15\t27\t8\t-1\t0.3\n",
      "空仓\t50\t0\t0\t-1\t1.0\n",
      "困顿\t19\t31\t0\t-1\t0.38\n",
      "财力\t5\t5\t40\t1\t0.8\n",
      "好逊\t29\t18\t3\t-1\t0.58\n",
      "不说了\t11\t33\t6\t-1\t0.22\n",
      "看空\t38\t12\t0\t-1\t0.76\n",
      "想一下\t20\t23\t7\t-1\t0.4\n",
      "亏大了\t47\t1\t2\t-1\t0.94\n",
      "为什么\t8\t31\t11\t1\t0.22\n",
      "好困惑\t22\t24\t4\t-1\t0.44\n",
      "赚大了\t0\t0\t50\t1\t1.0\n",
      "看多\t0\t0\t50\t1\t1.0\n"
     ]
    }
   ],
   "source": [
    "ls_all = expression_mark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 得到每句话的情感分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_df_label():\n",
    "    ##得到一个表情词典，key=表情符号 value=分值\n",
    "    expression_label_dict = {}\n",
    "    for i in ls_all:\n",
    "        expression_label_dict[i[0]] = i[-2]*i[-1]\n",
    "    ##遍历word_dict，得到其中每句话的情感分值，存入word_label_dict\n",
    "    word_label_dict = {}\n",
    "    for i in word_dict:\n",
    "        ex_ls = word_dict[i]\n",
    "        ex_ls = [x for x in ex_ls if x in expression_list]\n",
    "        label = sum([expression_label_dict[y] for y in ex_ls ])\n",
    "        word_label_dict[i] = label\n",
    "    ##转化为DataFrame\n",
    "    label = list(word_label_dict.values())\n",
    "    words = list(word_label_dict.keys())\n",
    "    df_label = pd.DataFrame()\n",
    "    df_label['content'] = words\n",
    "    df_label['label'] = label\n",
    "    return df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = gain_df_label()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练集构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_label.label.hist(bins = 100)画一下分值的直方图来直观感受一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct(num):\n",
    "    return np.percentile(df_label.label,num) \n",
    "\n",
    "#分类函数\n",
    "def label_classify(df_label):\n",
    "    pct25 = pct(20)\n",
    "    pct50 = pct(40)\n",
    "    pct75 = pct(60)\n",
    "    for i in range(len(df_label.label)):\n",
    "        label = df_label.iloc[i,1]\n",
    "        if label <= pct25:\n",
    "            df_label.iloc[i,1] = 0\n",
    "        elif pct25<label<pct50:\n",
    "            df_label.iloc[i,1] = 1\n",
    "        elif pct50<=label<pct75:\n",
    "            df_label.iloc[i,1] = 2\n",
    "        elif label>+pct75:\n",
    "            df_label.iloc[i,1] = 3\n",
    "    ##分词，去标点,去数字\n",
    "    df_label = jieba_and_clean(df_label)\n",
    "    ##储存\n",
    "    save_obj(df_label,'df_train_data')\n",
    "    #此处改为\n",
    "    #return df_label\n",
    "    #就可以看到处理的结果了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classify(df_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
